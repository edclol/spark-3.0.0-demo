#log4j.rootCategory=info, stdout
#log4j.rootLogger=info, stdout
#
#### stdout ###
#log4j.appender.stdout=org.apache.log4j.ConsoleAppender
#log4j.appender.stdout.Target=System.out
#log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
#log4j.appender.stdout.layout.ConversionPattern=[%t] [%p] [%d{yyyy-MM-dd HH:mm:ss}] %m %n
#
#
#log4j.logger.org.apache.spark.repl.Main=WARN
#
## Settings to quiet third party logs that are too verbose
#log4j.logger.org.spark_project.jetty=WARN
#log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR
#log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
#log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
#log4j.logger.org.apache.parquet=ERROR
#log4j.logger.parquet=ERROR
#
## SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
#log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
#log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR